{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from abc import ABC, abstractmethod\n",
    "from random import random\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "#initialize for random seeds/states\n",
    "tf.keras.backend.clear_session()\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "rng = np.random.default_rng(12345)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d7533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class paper_game(ABC):\n",
    "    def __init__(self, start_state):\n",
    "        self.state=start_state\n",
    "    \n",
    "    @abstractmethod\n",
    "    def transition(state, action, player):\n",
    "        #return next state\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def reward(self, state, action, player):\n",
    "        #return reward immediately after action\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def policy(self, state):\n",
    "        #return action\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Q_func(self, state, action):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Q_update(self, state, action, reward_1, maxQ, player):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7253efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tit_tac_toe(paper_game):\n",
    "#state: 3x3 array to represent board config, with 1 representing self-checker, -1 representing opponent-checker, 0 representing empty\n",
    "    def __init__(self, start_state=np.zeros((3,3), dtype=np.int8), epsilon=0.9, alpha=0.5, gamma=0.8):\n",
    "        self.state=start_state\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.Q = np.zeros((19683, 9))  #initialize Q matrix with state 'reference' (see ref function) and action key (see key function)    \n",
    "    \n",
    "    def transition(self, state, action, player):\n",
    "        #action: a list of row and column index to indicate which cell is chosen\n",
    "        #player: 1 or -1\n",
    "        #applicable to both tic_tac_toe and Connect-4\n",
    "        #return next state\n",
    "        new_state = copy.deepcopy(state)\n",
    "        new_state[action[0]][action[1]] = player\n",
    "        return new_state\n",
    "    \n",
    "    def win_status(self, s):\n",
    "        #s: state, \n",
    "        #return: whether win or not\n",
    "        win = 3 in np.sum(s, axis=0) or 3 in np.sum(s, axis=1) or np.sum(s.diagonal())==3 or np.sum(np.fliplr(s).diagonal())==3\n",
    "        return win\n",
    "\n",
    "    def lose_status(self, s):\n",
    "        #s: state, \n",
    "        #return: whether win or not\n",
    "        lose = -3 in np.sum(s, axis=0) or -3 in np.sum(s, axis=1) or np.sum(s.diagonal())==-3 or np.sum(np.fliplr(s).diagonal())==-3\n",
    "        return lose\n",
    "    \n",
    "    def ref(self, state):\n",
    "        #change state matrix into vector\n",
    "        ref = np.sum(np.matrix([1,3,3**2,3**3,3**4,3**5,3**6,3**7,3**8]) @ np.reshape((state + 1).flatten(),(9,1)))\n",
    "        return ref\n",
    "    \n",
    "    def key(self, action):\n",
    "        #change actions [r, c] into numbers 0-8\n",
    "        return 3*action[0]+action[1]\n",
    "    \n",
    "    def action_list(self, state):\n",
    "        act_list = np.where(state==0)\n",
    "        return act_list\n",
    "\n",
    "    def reward(self, state, action, player):\n",
    "        s = player * self.transition(state, action, player)\n",
    "        if self.win_status(s):\n",
    "            reward = 100\n",
    "        elif self.lose_status(s):\n",
    "            reward = -50\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward\n",
    "    \n",
    "    def Q_func(self, state, action):\n",
    "        Q = self.Q[self.ref(state)][self.key(action)]\n",
    "        return Q\n",
    "\n",
    "    def Q_update(self, state, action, reward_1, maxQ, player):\n",
    "        #state of board instead of current player's perspective\n",
    "        #reward_1: reward of player 1 regardless of who is current player\n",
    "        #maxQ: player's maxQ after another action\n",
    "        #player: 1 or -1\n",
    "        s = player*state\n",
    "        self.Q[self.ref(s)][self.key(action)] += self.alpha*(reward_1*player + self.gamma*maxQ - self.Q[self.ref(s)][self.key(action)] )\n",
    "\n",
    "\n",
    "    def random_move(self, state):\n",
    "        act_list = self.action_list(state)\n",
    "        i = np.random.randint(len(act_list[0]))\n",
    "        action = [act_list[0][i],act_list[1][i]]\n",
    "        return action\n",
    "\n",
    "    def best_move(self, state):\n",
    "        act_list = self.action_list(state)\n",
    "        maxQ = -10000\n",
    "        for i in range (len(act_list[0])):\n",
    "            a = [act_list[0][i],act_list[1][i]]\n",
    "            temp = self.Q_func(state, a)\n",
    "            if temp > maxQ:\n",
    "                maxQ = temp\n",
    "                action = a\n",
    "        return action, maxQ\n",
    "    \n",
    "    def policy(self, state):\n",
    "        exploit = (not self.train) or rng.random()> self.epsilon or self.play\n",
    "        if exploit:\n",
    "            action, maxQ = self.best_move(state)\n",
    "        else:\n",
    "            action = self.random_move(state)\n",
    "        if self.epsilon < 0.5:\n",
    "            self.epsilon *= 0.9999\n",
    "        else:\n",
    "            self.epsilon *= 0.99999    \n",
    "        return action\n",
    "    \n",
    "    def train(self, train_number=2000):\n",
    "        self.epochs = train_number\n",
    "        self.train = True\n",
    "        self.play = False\n",
    "        #loop by train_number\n",
    "        start_time = time.time()\n",
    "        for i in range (train_number):\n",
    "            if i % 10000 == 0 and i != 0:\n",
    "                end_time = time.time()\n",
    "                elp_time = '{:.2f}'.format(end_time - start_time)\n",
    "                print(f'Training Phase, epoch {i}, elapsed time:{elp_time}')\n",
    "                start_time = time.time()\n",
    "                \n",
    "            states =[]\n",
    "            state = self.state #start state\n",
    "            states.append(state)\n",
    "            actions=[]\n",
    "            r1=[0] #reward list at different times for player 1; for player -1: use zero sum property\n",
    "            t = 0\n",
    "            #choose who is X, i.e. plays first\n",
    "            player = 1 #as this is self-play, we simply assume 1 always plays first and be playerX\n",
    "            endgame = False\n",
    "            while not endgame:\n",
    "                #update his Q before action if previous has action\n",
    "                s = player * state\n",
    "                if t >=2:\n",
    "                    action, maxQ = self.best_move(s)\n",
    "                    self.Q_update(states[t-2], actions[t-2], r1[t], maxQ, player)\n",
    "                    \n",
    "                #action\n",
    "                action = self.policy(s)\n",
    "                actions.append(action)\n",
    "                t += 1\n",
    "                r1.append(player*self.reward(state, action, player))\n",
    "                state=self.transition(state, action, player)\n",
    "                states.append(state)\n",
    "                #check win status and end game status, update Q for both players if end game\n",
    "                endgame = self.win_status(s) or t==9\n",
    "                if endgame:\n",
    "                    self.Q_update(states[t-1], actions[t-1], r1[t], 0, player) #r1[t+1] is not used as there won't be t+1 when endgame is reached\n",
    "                    self.Q_update(states[t-2], actions[t-2], r1[t], 0, -player)\n",
    "                    \n",
    "                #update player for next loop\n",
    "                player *= -1\n",
    "        self.last_episode = states\n",
    "        \n",
    "    def display_board(self, state):\n",
    "        print('-------------------')\n",
    "        print(state)\n",
    "        print('-------------------')\n",
    "\n",
    "    def display_episode(self):\n",
    "        for i in range(len(self.last_episode)):\n",
    "            print('state {} :'.format(i))\n",
    "            self.display_board(self.last_episode[i])\n",
    "            \n",
    "    def play_game(self,starter = -1):\n",
    "        self.play = True\n",
    "        self.train = False\n",
    "        state = np.zeros((3,3), dtype=np.int8)\n",
    "        \n",
    "        endgame = False\n",
    "        t = 0\n",
    "        self.display_board(state)\n",
    "        while not endgame:\n",
    "            if starter == -1:\n",
    "                i = int(input('enter row:\\n'))\n",
    "                j = int(input('enter column:\\n'))\n",
    "                state[i,j] = -1\n",
    "\n",
    "            else:\n",
    "                i,j = self.best_move(state)[0]\n",
    "                state[i,j] = 1\n",
    "\n",
    "            self.display_board(state)   \n",
    "            starter *= -1\n",
    "            t += 1\n",
    "            endgame = self.win_status(state) or self.lose_status(state) or t==9\n",
    "            \n",
    "                    \n",
    "   \n",
    "    def play_gui(self):\n",
    "\n",
    "        self.play = True\n",
    "        self.train = False\n",
    "        state = np.zeros((3,3), dtype=np.int8)\n",
    "        \n",
    "        endgame = False\n",
    "        t = 0\n",
    "        \n",
    "        win = tk.Tk()\n",
    "        win.geometry(\"240x380\")\n",
    "\n",
    "        def next_turn(i,j,button_id):\n",
    "            nonlocal t\n",
    "            state[i,j] = -1\n",
    "\n",
    "            var[button_id].set('X')\n",
    "            button[button_id].config(state = 'disabled')\n",
    "            \n",
    "            if self.lose_status(state):\n",
    "                option = messagebox.askyesno('Finished!','You Won! Do you want to play again?')\n",
    "                if option == True:\n",
    "                    win.destroy()\n",
    "                    self.play_gui()\n",
    "                else:\n",
    "                    win.destroy()\n",
    "                return None\n",
    "                \n",
    "            t += 1\n",
    "            \n",
    "            if t == 9:\n",
    "                option = messagebox.askyesno('Finished!','Draw! Do you want to play again?')\n",
    "                if option == True:\n",
    "                    win.destroy()\n",
    "                    self.play_gui()\n",
    "                else:\n",
    "                    win.destroy()\n",
    "                return None\n",
    "\n",
    "            i,j = self.best_move(state)[0]                \n",
    "            state[i,j] = 1\n",
    "            var[i * 3 + j].set('O')\n",
    "            button[i * 3 + j].config(state = 'disabled')\n",
    "            \n",
    "            if self.win_status(state):\n",
    "                option = messagebox.askyesno('Finished!','You Lost! Do you want to play again?')\n",
    "                if option == True:\n",
    "                    win.destroy()\n",
    "                    self.play_gui()\n",
    "                else:\n",
    "                    win.destroy()\n",
    "                return None\n",
    "                    \n",
    "            t += 1\n",
    "            \n",
    "            if t == 9:\n",
    "                option = messagebox.askyesno('Finished!','Draw! Do you want to play again?')\n",
    "                if option == True:\n",
    "                    win.destroy()\n",
    "                    self.play_gui()\n",
    "                else:\n",
    "                    win.destroy()\n",
    "                return None\n",
    "\n",
    "          \n",
    "        var = []\n",
    "        button = []\n",
    "        game_frame = tk.Frame(win)\n",
    "        for i in range(9):\n",
    "            v = tk.StringVar()\n",
    "            var.append(v)\n",
    "            m = int(i)\n",
    "            b = tk.Button(game_frame,  textvariable = v, height= 5, width=10, state = 'disabled')\n",
    "            button.append(b)\n",
    "            b.grid(row = i //3 + 1, column = i % 3)\n",
    "\n",
    "        game_title = tk.Label(win,text = 'TIC TAC TOE')\n",
    "        game_title.pack()\n",
    "        game_frame.pack()\n",
    "        button[0].config(command = lambda:next_turn(0,0,0))\n",
    "        button[1].config(command = lambda:next_turn(0,1,1))\n",
    "        button[2].config(command = lambda:next_turn(0,2,2))\n",
    "        button[3].config(command = lambda:next_turn(1,0,3))\n",
    "        button[4].config(command = lambda:next_turn(1,1,4))\n",
    "        button[5].config(command = lambda:next_turn(1,2,5))\n",
    "        button[6].config(command = lambda:next_turn(2,0,6))\n",
    "        button[7].config(command = lambda:next_turn(2,1,7))\n",
    "        button[8].config(command = lambda:next_turn(2,2,8))\n",
    "        starting_player = tk.Label(win,text = 'First Player:')\n",
    "        game_variable = tk.StringVar()\n",
    "        game_option1 = tk.Radiobutton(win, text = 'BOT', variable = game_variable, value = 'BOT')\n",
    "        game_option2 = tk.Radiobutton(win, text = 'Player', variable = game_variable, value = 'player')\n",
    "        starting_player.pack()\n",
    "        game_option1.pack()\n",
    "        game_option2.pack()\n",
    "        \n",
    "        \n",
    "        def initiating():\n",
    "            nonlocal t\n",
    "            for b in button:\n",
    "                b.config(state = 'normal',bg = 'white')\n",
    "\n",
    "            if game_variable.get() == 'BOT':\n",
    "                i,j = self.best_move(state)[0]                \n",
    "                state[i,j] = 1\n",
    "                var[i * 3 + j].set('O')\n",
    "                button[i * 3 + j].config(state = 'disabled')\n",
    "                t+= 1\n",
    "\n",
    "        start_button = tk.Button(win,text = 'Start Game', command = initiating)\n",
    "        start_button.pack()\n",
    "\n",
    "        \n",
    "        win.mainloop()\n",
    "        \n",
    "    def save_Q(self):\n",
    "        np.savetxt(f\"Q-{self.epochs}.csv\", self.Q, delimiter=\",\")\n",
    "        \n",
    "    def load_Q(self,file):\n",
    "        self.Q = np.loadtxt(file, delimiter=\",\")\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273fb8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can create a game just by loading previous Q matrix\n",
    "\n",
    "test2 = tit_tac_toe()\n",
    "test2.load_Q('Q-150000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c62985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing game with graphical interface\n",
    "\n",
    "test2.play_gui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c8d23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training new game\n",
    "\n",
    "test1 = tit_tac_toe()\n",
    "test1.train(150000)\n",
    "test1.display_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a867bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing game with inline commands\n",
    "\n",
    "test1.play_game(-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
